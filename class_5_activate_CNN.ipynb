{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n神经网络的训练\\n反向传播算法：\\n    用已知的信息标签和预测结果进行比对，算出差值，用这个差值反向算出所有的权重\\n损失函数：\\n    1、L1直接误差\\n    2、L2平方误差\\n    3、交叉熵（分类用到的多，卷积用到的多）\\n找到神经网络的权重w，偏差b去最小化损失函数L（不论是1、2、3）\\n\\n训练方法：梯度（斜率）下降法\\n\\n卷积神经网络：\\n    1、卷积层：\\n        顾名思义，就是由一个算子做卷积运算，但是卷积算子是通过反向传播算法计算出的具体值（相当于w），\\n        可以有很多层，每一层都可和图像做卷积运算。\\n        卷积步长stride：就是每次挪动几个格子（eg：1的话就是每次挪动一个格，2就是每次挪动2个格）\\n        padding：在外加层，padding=1就是加一层，=2时会加2层\\n        卷积后图像大小：(n+2p-f)/s +1 ,其中n为图片大小，p为padding f为卷积算子大小，s为步长\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "神经网络的训练\n",
    "反向传播算法：\n",
    "    用已知的信息标签和预测结果进行比对，算出差值，用这个差值反向算出所有的权重\n",
    "损失函数：\n",
    "    1、L1直接误差\n",
    "    2、L2平方误差\n",
    "    3、交叉熵（分类用到的多，卷积用到的多）\n",
    "找到神经网络的权重w，偏差b去最小化损失函数L（不论是1、2、3）\n",
    "\n",
    "训练方法：梯度（斜率）下降法\n",
    "\n",
    "卷积神经网络：\n",
    "    1、卷积层：\n",
    "        顾名思义，就是由一个算子做卷积运算，但是卷积算子是通过反向传播算法计算出的具体值（相当于w），\n",
    "        可以有很多层，每一层都可和图像做卷积运算。\n",
    "        卷积步长stride：就是每次挪动几个格子（eg：1的话就是每次挪动一个格，2就是每次挪动2个格）\n",
    "        padding：在外加层，padding=1就是加一层，=2时会加2层\n",
    "        卷积后图像大小：(n+2p-f)/s +1 ,其中n为图片大小，p为padding f为卷积算子大小，s为步长\n",
    "        如果是RGB3维图像卷积或者高纬度卷积，就是每一个通道卷积然后取平均的结果\n",
    "    2、池化层（非线性的处理）：\n",
    "        步长：同上\n",
    "        算子大小：同上\n",
    "        maxpooling：找最大\n",
    "        averagepooling：求平均\n",
    "    3、全连接层：\n",
    "        一般放在网络的最后部分，用于输出和分析结果，相当于一个分类器\n",
    "        卷积后是多维的，把数据都输入一个全连接神经元中（有多少神经元输入多少次），输出一个最后的预测结果\n",
    "        SVM\n",
    "        FCN\n",
    "        全局池化\n",
    "        \n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "经典结构：\n",
    "1、Alexnet\n",
    "2、ResNet（残差神经网络）：将原始的输入和处理后的输出叠加在一起，生成一个矩阵，在把其传递到下一层，可以解决梯度问题\n",
    "3、InceptionNet：将各个尺寸的卷积核放在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "梯度消失\n",
    "导数小于1，多次之后，就没了\n",
    "\n",
    "梯度爆炸\n",
    "导数大于1，多次之后，就很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
